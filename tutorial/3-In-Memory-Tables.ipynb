{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Objectives:\n",
    "> * Compare queries of tabular data for **in-memory** containers\n",
    "> * Compare sizes and times for those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipython_memwatcher import MemWatcher\n",
    "mw = MemWatcher()\n",
    "mw.start_watching_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "dset = 'movielens-1m'\n",
    "fdata = os.path.join(dset, 'ratings.dat.gz')\n",
    "fitem = os.path.join(dset, 'movies.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pass in column names for each CSV\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv(fdata, sep=';', names=r_cols, compression='gzip')\n",
    "\n",
    "m_cols = ['movie_id', 'title', 'genres']\n",
    "movies = pd.read_csv(fitem, sep=';', names=m_cols,\n",
    "                     dtype={'title': object, 'genres': object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lens = pd.merge(movies, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_pandas = mw.measurements.memory_delta\n",
    "size_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pandas also comes with its own tool for getting memory usage\n",
    "print(lens.memory_usage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "1) Why do you think that the size is the same for every column in the dataframe?\n",
    "\n",
    "*Hint:* pandas stores the string columns in NumPy containers with 'object' dtype.\n",
    "\n",
    "2) Provided how the `lens` DataFrame looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lens.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you think this is all the memory that the DataFrame tables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use deep=True for including the size of the object types\n",
    "print(lens.memory_usage(deep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For a more realistic memory usage, we are going to use deep=True\n",
    "size_pandas2 = lens.memory_usage(deep=True).sum() / 2**20.\n",
    "size_pandas2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's do a typical query in pandas and see how fast it can be\n",
    "t = %timeit -o lens.query(\"(title == 'Tom and Huck (1995)') & (rating == 5)\")['user_id']\n",
    "result = lens.query(\"(title == 'Tom and Huck (1995)') & (rating == 5)\")['user_id']\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store it for future reference\n",
    "qtime_pandas = t.best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a compressed in-memory container via `bcolz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "bcolz.print_versions()\n",
    "bcolz.defaults.cparams['cname'] = 'lz4'\n",
    "bcolz.defaults.cparams['clevel'] = 9\n",
    "bcolz.defaults.cparams['shuffle'] = bcolz.BITSHUFFLE  # try with NOSHUFFLE and BITSHUFFLE as well\n",
    "bcolz.set_nthreads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zlens = bcolz.ctable.fromdataframe(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_bcolz = mw.measurements.memory_delta\n",
    "size_bcolz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the reported memory consumption is *really* low, so let's take the internal estimation for comparison purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_bcolz2 = zlens.cbytes / 2**20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_pandas2 / size_bcolz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying a bcolz ctable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Workaround to use bytes instead of Unicode (not supported yet in numexpr queries)\n",
    "title = zlens['title'][:].astype('S82')\n",
    "zlens.delcol('title')\n",
    "zlens.addcol(title, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Workaround to use bytes instead of Unicode (not supported yet in numexpr queries)\n",
    "genre = zlens['genres'][:].astype('S47')\n",
    "zlens.delcol('genres')\n",
    "zlens.addcol(genre, 'genres')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the space taken by a bcolz container is around 20x smaller (!) than a pandas one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Querying a bcolz dataset\n",
    "resultz = [(r.nrow__, r.user_id) for r in zlens.where(\"(title == b'Tom and Huck (1995)') & (rating == 5)\", outcols=['nrow__', 'user_id'])]\n",
    "t = %timeit -o [(r.nrow__, r.user_id) for r in zlens.where(\"(title == b'Tom and Huck (1995)') & (rating == 5)\", outcols=['nrow__', 'user_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qtime_bcolz = t.best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qtime_pandas / qtime_bcolz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that by using a compressed bcolz container, it provides similar query times than pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sanity check (always check for your results!)\n",
    "print(\"results with pandas Dataframe:\", result)\n",
    "print(\"results with bcolz ctable:\", resultz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a *uncompressed* in-memory container via `bcolz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what happens when we use an uncompressed container in bcolz?  We do expect better speed?  If so, how much?  Let's measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bcolz.defaults.cparams['clevel'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uzlens = bcolz.ctable.fromdataframe(lens)\n",
    "uzlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_ubcolz = mw.measurements.memory_delta\n",
    "size_ubcolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_ubcolz2 = uzlens.cbytes / 2**20.\n",
    "size_ubcolz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_pandas2 / size_ubcolz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the space taken by an uncompressed bcolz container is very close to a pandas one (but keep an eye on the reported memory usage by memory_watcher)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Workaround to use bytes instead of Unicode (not supported yet in numexpr queries)\n",
    "title = zlens['title'][:].astype('S82')\n",
    "uzlens.delcol('title')\n",
    "uzlens.addcol(title, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Querying a bcolz dataset\n",
    "resultz = [(r.nrow__, r.user_id) for r in uzlens.where(\"(title == b'Tom and Huck (1995)') & (rating == 5)\", outcols=['nrow__', 'user_id'])]\n",
    "t = %timeit -o [(r.nrow__, r.user_id) for r in uzlens.where(\"(title == b'Tom and Huck (1995)') & (rating == 5)\", outcols=['nrow__', 'user_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qtime_ubcolz = t.best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qtime_pandas / qtime_ubcolz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using structured NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nalens = zlens[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_numpy = mw.measurements.memory_delta\n",
    "size_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nalens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_numpy2 = round((nalens.size * nalens.dtype.itemsize) / 2**20., 3)\n",
    "size_numpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# But, again, this does not account for 'O'bject dtypes, which are stored in its own storage area\n",
    "# So, let's take this into account\n",
    "import sys\n",
    "size_numpy3 = size_numpy2 + round(sum(sum(sys.getsizeof(o) for o in nalens[col]) for col in ('title', 'genres')) // 2**20., 3)\n",
    "size_numpy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultna = nalens[(nalens['title'] == 'Tom and Huck (1995)') & (nalens['rating'] == 5)]\n",
    "t = %timeit -o nalens[(nalens['title'] == 'Tom and Huck (1995)') & (nalens['rating'] == 5)]\n",
    "resultna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, NumPy works the fastest for in-memory data containers, while memory consumption is close to pandas (a hair less actually)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qtime_numpy = t.best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance comparsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Query times\n",
    "labels = [\"pandas\", \"bcolz\", \"uncompressed bcolz\", \"numpy (recarray)\"]\n",
    "df = pd.DataFrame({'time (sec)': [qtime_pandas, qtime_bcolz, qtime_ubcolz, qtime_numpy]}, index=labels)\n",
    "pd.options.display.mpl_style = 'default'\n",
    "df.plot(kind='barh', figsize=(12,5), fontsize=16, title=\"Query times for MovieLens 1m (in-memory)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Container sizes\n",
    "df = pd.DataFrame({'size (MB)': [size_pandas2, size_bcolz2, size_ubcolz2, size_numpy3]}, index=labels)\n",
    "pd.options.display.mpl_style = 'default'\n",
    "df.plot(kind='barh', figsize=(12,5), fontsize=16, title=\"Container sizes for MovieLens 1m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules of thumb for querying in-memory tabular datasets\n",
    "\n",
    "* Choose pure NumPy recarrays if you need the fastest speed\n",
    "* Choose bcolz ctables if you need to store lots of data in limited memory and not want to loose too much speed\n",
    "* Choose pandas if what you need is rich functionality on top of your containers (at the penalty of some speed)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
