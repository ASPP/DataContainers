{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Reduction Tale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Objectives:\n",
    "> * Compare operations taking place in different data containers\n",
    "> * Compare sizes for these data containers\n",
    "> * Help deciding when it is best to use a container or another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose that we are going to need reductions a lot and we want to choose the best container for performing them.  First, let's start by activating our MemWatcher agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [1] used 0.000 MiB RAM in 0.001s, peaked 0.000 MiB above current, total RAM usage 41.301 MiB\n"
     ]
    }
   ],
   "source": [
    "if 'MemWatcher' not in dir():\n",
    "    from ipython_memwatcher import MemWatcher\n",
    "    mw = MemWatcher()\n",
    "    mw.start_watching_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and choose a different container for the data that we want to reduce, starting with a list:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [2] used 311.777 MiB RAM in 1.476s, peaked 0.000 MiB above current, total RAM usage 353.078 MiB\n"
     ]
    }
   ],
   "source": [
    "a = [float(i) for i in range(10*1000*1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, proceed with a simple reduction (sum):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 43.1 ms per loop\n",
      "In [3] used 0.176 MiB RAM in 1.802s, peaked 0.000 MiB above current, total RAM usage 353.254 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which, in MFLOPS (Mega-FloatingPointOps-Per-Second) is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFLOPS: 232.2\n",
      "In [4] used 0.082 MiB RAM in 0.001s, peaked 0.000 MiB above current, total RAM usage 353.336 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"MFLOPS:\", round((len(a) / t.best / 1e6), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so that seems fast, but we don't have other references to compare with.  In addition, a list is not the best kind of container in terms of space consumption.  So let's try now a container that seems quite optimal in terms of memory savings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [5] used 13.430 MiB RAM in 0.235s, peaked 0.000 MiB above current, total RAM usage 366.766 MiB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [6] used 74.504 MiB RAM in 0.199s, peaked 0.000 MiB above current, total RAM usage 441.270 MiB\n"
     ]
    }
   ],
   "source": [
    "na = np.array(a, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZE: 76.294\n",
      "In [7] used 0.008 MiB RAM in 0.001s, peaked 0.000 MiB above current, total RAM usage 441.277 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"SIZE:\", round((na.size * na.itemsize) / 2**20., 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that, with 8 bytes/element, NumPy is a very efficient container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 712 ms per loop\n",
      "In [8] used 0.000 MiB RAM in 2.855s, peaked 0.000 MiB above current, total RAM usage 441.277 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o sum(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFLOPS: 14.049\n",
      "In [9] used 0.000 MiB RAM in 0.001s, peaked 0.000 MiB above current, total RAM usage 441.277 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"MFLOPS:\", round(len(a) / t.best / 1e6, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance for NumPy is several times slower than the computation with the list.  Why so?\n",
    "\n",
    "*Hint: * We are using sum() which is a Python function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy has a lot of overhead in producing a Python integer for every element in the array for feeding it to the sum().\n",
    "\n",
    "*Hint:* Use internal NumPy methods (ufuncs) when possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 3.46 ms per loop\n",
      "In [10] used 0.000 MiB RAM in 1.436s, peaked 0.000 MiB above current, total RAM usage 441.277 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o na.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPS: 2886.848\n",
      "In [11] used 0.000 MiB RAM in 0.001s, peaked 0.000 MiB above current, total RAM usage 441.277 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"FLOPS:\", round(len(a) / t.best / 1e6, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is more than 100x the speed of sum() on a Python list and it is also pretty optimal in terms of both execution time and space consumed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "The speed in the above reduction is limited by memory speed, not CPU speed.  Could you provide a hint on the maximum memory speed that supports your laptop?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.508695521565222"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [12] used 0.000 MiB RAM in 0.006s, peaked 0.000 MiB above current, total RAM usage 441.277 MiB\n"
     ]
    }
   ],
   "source": [
    "# This is an easy one.  Just divide the size of the dataset by the time that takes the reduction\n",
    "(na.size * na.itemsize) / t.best / 2**30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in this case the memory bandwidth is ~ 17 GB/s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using compressed in-memory containers with bcolz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But let us suppose that we have really big data to process in our laptop and want to see if we can store our data in less space.  Enter compression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "bcolz version:     1.1.1.dev16\n",
      "bcolz git info:    b'1.1.0-16-g6a40395'\n",
      "NumPy version:     1.11.1\n",
      "Blosc version:     1.9.3 ($Date:: 2016-07-06 #$)\n",
      "Blosc compressors: ['blosclz', 'lz4', 'lz4hc', 'snappy', 'zlib']\n",
      "Numexpr version:   2.6.1\n",
      "Dask version:      0.11.0\n",
      "Python version:    3.5.2 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "Platform:          linux-x86_64\n",
      "Byte-ordering:     little\n",
      "Detected cores:    8\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [13] used 37.254 MiB RAM in 0.445s, peaked 0.000 MiB above current, total RAM usage 478.531 MiB\n"
     ]
    }
   ],
   "source": [
    "import bcolz\n",
    "bcolz.print_versions()\n",
    "bcolz.defaults.cparams['cname'] = 'lz4hc'\n",
    "bcolz.defaults.cparams['clevel'] = 3\n",
    "bcolz.defaults.cparams['shuffle'] = bcolz.SHUFFLE\n",
    "bcolz.set_nthreads(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [14] used 2.504 MiB RAM in 0.034s, peaked 0.000 MiB above current, total RAM usage 481.035 MiB\n"
     ]
    }
   ],
   "source": [
    "ca = bcolz.carray(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem_used: 2.50390625\n",
      "In [15] used 0.000 MiB RAM in 0.001s, peaked 0.000 MiB above current, total RAM usage 481.035 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"mem_used:\", mw.measurements.memory_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, bcolz containers can provide an estimation on how much memory they are taking; let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carray((10000000,), float64)\n",
       "  nbytes := 76.29 MB; cbytes := 1.40 MB; ratio: 54.51\n",
       "  cparams := cparams(clevel=3, shuffle=1, cname='lz4hc', quantize=0)\n",
       "  chunklen := 65536; chunksize: 524288; blocksize: 131072\n",
       "[  0.00000000e+00   1.00000000e+00   2.00000000e+00 ...,   9.99999700e+06\n",
       "   9.99999800e+06   9.99999900e+06]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [16] used 0.539 MiB RAM in 0.002s, peaked 0.000 MiB above current, total RAM usage 481.574 MiB\n"
     ]
    }
   ],
   "source": [
    "ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we see that bcolz estimation is reasonably close to `ipython_memwatcher` measurements.  Let's have a look at the speed of the reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 12 ms per loop\n",
      "MFLOPS: 834.72\n",
      "In [17] used 0.121 MiB RAM in 4.913s, peaked 0.000 MiB above current, total RAM usage 481.695 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o ca.sum()\n",
    "print(\"MFLOPS:\", round(len(a) / t.best / 1e6, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is around 2~5x slower (depending on the machine) than a regular NumPy array, but the size of the array is a quite impressive 50x smaller.  But is compression the only responsible of the overhead?  Let's investigate a bit further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using uncompressed containers with bcolz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In order to see if this is because of the compression overhead, let's use an uncompressed array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [18] used 76.535 MiB RAM in 0.259s, peaked 3.242 MiB above current, total RAM usage 558.230 MiB\n"
     ]
    }
   ],
   "source": [
    "cau = bcolz.carray(a, cparams=bcolz.cparams(clevel=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carray((10000000,), float64)\n",
       "  nbytes := 76.29 MB; cbytes := 76.50 MB; ratio: 1.00\n",
       "  cparams := cparams(clevel=0, shuffle=1, cname='lz4hc', quantize=0)\n",
       "  chunklen := 65536; chunksize: 524288; blocksize: 65536\n",
       "[  0.00000000e+00   1.00000000e+00   2.00000000e+00 ...,   9.99999700e+06\n",
       "   9.99999800e+06   9.99999900e+06]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [19] used 0.000 MiB RAM in 0.002s, peaked 0.000 MiB above current, total RAM usage 558.230 MiB\n"
     ]
    }
   ],
   "source": [
    "cau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 7.42 ms per loop\n",
      "MFLOPS: 1348.591\n",
      "In [20] used 0.020 MiB RAM in 3.066s, peaked 0.000 MiB above current, total RAM usage 558.250 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o cau.sum()\n",
    "print(\"MFLOPS:\", round(len(a) / t.best / 1e6, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the times with an uncompressed `carray` are noticieably faster than with a compressed one, so compressing is not the only source of the overhead.  The other source of the difference is the memory layout of the different containers (bcolz's carray data container layout is a bit more complex than NumPy).\n",
    "\n",
    "So, while bcolz allows to use compressed in-memory data containers, this usually represents more cost in performance (compared with NumPy).  But sometimes you may prefer to keep more data in-memory and assume that the computations are going to be slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "bcolz uses Blosc, a multithreaded meta-compressor, to do the compression under the hood.  Blosc can use different codecs, and each one has different behavior in terms of performance.  Given the next computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 13.1 ms per loop\n",
      "carray sizes--> uncompr: 76.294 MB, compr: 0.994 MB, ratio: 76.719\n",
      "In [21] used 2.859 MiB RAM in 5.397s, peaked 0.000 MiB above current, total RAM usage 561.109 MiB\n"
     ]
    }
   ],
   "source": [
    "bcolz.defaults.cparams['cname'] = 'blosclz'   # try also with 'lz4', 'lz4hc', 'zlib'\n",
    "bcolz.defaults.cparams['clevel'] = 9          # try from 1 to 9\n",
    "bcolz.defaults.cparams['shuffle'] = bcolz.SHUFFLE   # try with bcolz.NOSHUFFLE and bcolz.BITSHUFFLE too\n",
    "bcolz.set_nthreads(8)\n",
    "ca = bcolz.carray(na)\n",
    "%timeit ca.sum()\n",
    "print(\"carray sizes--> uncompr: %.3f MB, compr: %.3f MB, ratio: %.3f\" % (\n",
    "    ca.nbytes / 2.**20, ca.cbytes/ 2**20., (ca.nbytes / ca.cbytes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with the different parameters and see:\n",
    "\n",
    "1) Which provides the best compression\n",
    "\n",
    "2) Which the fastest speed\n",
    "\n",
    "3) The combination that strikes a good balance between compression and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Athough this is somewhat system dependent, the codecs that usually provides the best compression are 'zlib' and 'lz4hc', whereas the ones that provided best speed are 'blosclz' and 'lz4'.  The one that strikes a good trade-off is probably 'lz4' with compression level > 6."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
